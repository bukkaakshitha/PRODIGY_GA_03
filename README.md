# Markov Chain Text Generator â€“ PRODIGY_GA_03

This project explores how simple probabilistic models can be used to generate text.  
Using a **Markov Chain**, the next word is predicted based on the previous one or two, enabling generation of new, pseudo-random sentences trained on a sample corpus.

---

## ðŸ“„ Overview

- ðŸ“˜ Internship Track: Generative AI  
- ðŸ”– Task Code: PRODIGY_GA_03  
- ðŸ¢ Organization: Prodigy InfoTech

---

## ðŸ” Project Highlights

- Tokenized a text corpus to construct n-gram chains  
- Built a transition dictionary mapping sequences to likely next words  
- Used random sampling to simulate "intelligent" sentence creation  
- Demonstrated the power of classic probabilistic models in NLP

---

## ðŸ“¦ Contents

- `mct2.ipynb - Colab.html`: Full implementation in Python  
- `README.md`: This documentation

---

## ðŸ› ï¸ Tech Stack

- Python  
- Jupyter / Colab  
- Core Concepts: n-grams, randomness, transition models

---

## ðŸš€ Outcome

This task helped reinforce how much can be done with minimal machine learning. Markov Chains remain a powerful foundation for understanding the building blocks of language models.

> #ProdigyInfoTech #GenerativeAI #MarkovChain #NLP #AIInternship #TextGeneration
