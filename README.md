# Markov Chain Text Generator – PRODIGY_GA_03

This project explores how simple probabilistic models can be used to generate text.  
Using a **Markov Chain**, the next word is predicted based on the previous one or two, enabling generation of new, pseudo-random sentences trained on a sample corpus.

---

## 📄 Overview

- 📘 Internship Track: Generative AI  
- 🔖 Task Code: PRODIGY_GA_03  
- 🏢 Organization: Prodigy InfoTech

---

## 🔍 Project Highlights

- Tokenized a text corpus to construct n-gram chains  
- Built a transition dictionary mapping sequences to likely next words  
- Used random sampling to simulate "intelligent" sentence creation  
- Demonstrated the power of classic probabilistic models in NLP

---

## 📦 Contents

- `mct2.ipynb - Colab.html`: Full implementation in Python  
- `README.md`: This documentation

---

## 🛠️ Tech Stack

- Python  
- Jupyter / Colab  
- Core Concepts: n-grams, randomness, transition models

---

## 🚀 Outcome

This task helped reinforce how much can be done with minimal machine learning. Markov Chains remain a powerful foundation for understanding the building blocks of language models.

> #ProdigyInfoTech #GenerativeAI #MarkovChain #NLP #AIInternship #TextGeneration
